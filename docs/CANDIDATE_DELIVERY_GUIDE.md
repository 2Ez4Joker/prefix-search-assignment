# Инструкция для кандидатов

Этот репозиторий содержит задание «Ранжирование префиксного поиска». Прочитайте документ `assignment/PREFIX_TEST_ASSIGNMENT.md` и выполните шаги ниже, чтобы подготовить своё решение.

## 1. Что ожидается от вас
1. Разверните любой выбранный движок поиска (Elasticsearch/OpenSearch, Milvus/Faiss, гибрид и т.д.) локально или в Docker.
2. Загрузите предоставленный каталог `data/catalog_products.xml` (≈1000 позиций) и обеспечьте обработку префиксных запросов из `data/prefix_queries.csv` (30 открытых + 30 скрытых кейсов).
3. Реализуйте ранжирование, учитывающее:
   - короткие префиксы, транслитерацию, смешанные раскладки;
   - сохранение числовых признаков (вес, объём, размер);
   - защиту от нерелевантных ответов в выдаче.
4. Снимите метрики качества (precision@K, доля правильных категорий, latency и т.п.) и приложите результаты в `evaluate.py`/ноутбуке.
5. Опишите архитектуру и принятые решения в README (см. раздел «Reflection» в задании).

## 2. Как оформить работу
1. **Форк / приватный репозиторий.** Создайте свой приватный репозиторий и добавьте туда содержимое решения. Ссылку на исходный репозиторий (этот) оставлять не обязательно.
2. **Docker-образ.**
   - Заверните сервис в Docker (желательно `docker-compose` или `Makefile run`).
   - Убедитесь, что образ можно запустить одной командой: `docker compose up` или `docker run ...`.
   - Загрузите образ в любой реестр (Docker Hub, Yandex Container Registry и т.д.) и приложите ссылку.
3. **Документация.** В корне вашего репозитория должен быть `README` со структурой:
   - требования к окружению;
   - шаги запуска (локально и через Docker);
   - описание схемы индекса и используемых анализаторов;
   - перечисление ключевых сценариев из `prefix_queries.csv` и как вы их покрыли;
   - результаты метрик и выводы («Reflection»);
   - раздел «Что бы я сделал в проде» (мониторинг, алерты, roadmap).
4. **Артефакты.**
   - Логи/скриншоты запросов приветствуются (положите в `reports/` или приложите ссылки).
   - Если вы добавляете дополнительные данные, не забывайте указывать источник и формат.

## 3. Что прислать интервьюеру
1. Ссылку на ваш git-репозиторий (GitHub/GitLab/Bitbucket). Репозиторий должен быть приватным; дайте доступ interviewers@diginetica.ru или указанному контакту.
2. Ссылку на Docker-образ и/или архив с готовым образом.
3. Короткую инструкцию (можно reuse README) с командами запуска.
4. Любые дополнительные материалы: презентации, графики, записи метрик.

## 4. Критерии оценки (суммируются)
| Область | Баллы | Пояснение |
| --- | --- | --- |
| Импорт данных и схема | 2 | Наличие скрипта загрузки, осмысленная структура индекса. |
| Ранжирование и обработка префиксов | 3 | Релевантность top-N, работа с опечатками, фильтры по атрибутам. |
| Метрики и тесты | 2 | Наличие `evaluate.py`/ноутбука, отчётов, объяснение результатов. |
| Документация и системное мышление | 2 | Понятный README, архитектура, roadmap. |
| Инициативы сверх задания | 1 | Вектора, LLM, эксперименты, нестандартные инсайты. |

Порог прохождения — 6+ баллов. Отсутствие README или Docker-образа автоматически снижает оценку.

## 5. Чек-лист перед сдачей
- [ ] Все команды запуска проверены на «чистой» машине / Docker.
- [ ] `load_catalog.py` (или аналог) воспроизводит импорт каталога.
- [ ] `evaluate.py` экспортирует CSV/JSON с итогами топ-5 для открытых запросов.
- [ ] README описывает подходы к сокращениям и транслитерации.
- [ ] В отчёте есть раздел о том, как вы уменьшаете «мусор» и как измеряете качество.
- [ ] Docker-образ опубликован и подписан тэгом `prefix-search-<Фамилия>`.

Удачи! Вопросы можно направлять через рекрутера или контактное лицо из письма.
